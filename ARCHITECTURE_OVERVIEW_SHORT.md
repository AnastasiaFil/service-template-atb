# Архитектура репликации данных Oracle → PostgreSQL

## Описание

Эта система автоматически реплицирует данные из Oracle в PostgreSQL в реальном времени. Когда в Oracle добавляется,
изменяется или удаляется запись, эти изменения автоматически попадают в PostgreSQL через несколько секунд.

Используется технология Change Data Capture (CDC), которая отслеживает все изменения в исходной базе данных Oracle и
передает их через Kafka в целевую базу PostgreSQL с промежуточной обработкой и обогащением данных через ksqlDB.

## Архитектура

```
┌─────────────────────────────────────────────────────────┐
│              Oracle Database                            │
└───────────────────────┬─────────────────────────────────┘
                        │
                        │ Debezium читает журнал изменений
                        │ Oracle (redo logs через LogMiner)
                        ▼
┌─────────────────────────────────────────────────────────┐
│     Kafka Connect (устанавливается как сервис)          │
│      + Debezium Oracle Connector (plugin)               │
│                                                         │
│  Что делает:                                            │
│  - Отслеживает все изменения в Oracle                   │
│  - Фиксирует INSERT, UPDATE, DELETE операции            │
│  - Отправляет изменения в Kafka                         │
└───────────────────────┬─────────────────────────────────┘
                        │
                        │ Поток событий изменений
                        ▼
┌─────────────────────────────────────────────────────────┐
│            Apache Kafka                                 │
│  Топики (очереди сообщений):                            │
│  - oracle_cdc.<schema>.<table_name>                     │
│           (для каждой реплицируемой таблицы)            │
└───────────────────────┬─────────────────────────────────┘
                        │
                        │ Чтение потоков данных
                        ▼
┌─────────────────────────────────────────────────────────┐
│            ksqlDB Server                                │
│            (устанавливается как сервис)                 │
│                                                         │
│  Что делает:                                            │
│    - Читает данные из топиков Kafka                     │
│    - Объединяет (JOIN) данные из связанных таблиц       │
│    - Создает обогащенную (денормализованную) таблицу    │
│    - Записывает результат в новый топик Kafka           │
└───────────────────────┬─────────────────────────────────┘
                        │
                        │ Обогащенные данные
                        ▼
┌─────────────────────────────────────────────────────────┐
│               Kafka Topic (Enriched Data)               │
│                 <enriched_topic_name>                   │
│                                                         │
│  Содержит готовые данные:                               │
│  денормализованные записи с объединенными полями (JOIN) │
└───────────────────────┬─────────────────────────────────┘
                        │
                        │ Чтение обогащенных данных
                        ▼
┌─────────────────────────────────────────────────────────┐
│        Kafka Connect (отдельный не нужен)               │
│          + JDBC Sink Connector (plugin)                 │
│                                                         │
│  Что делает:                                            │
│  - Читает обогащенные данные из Kafka                   │
│  - Преобразует форматы (переименовывает поля,           │
│    конвертирует даты)                                   │
│  - Записывает данные в PostgreSQL                       │
│  - Использует UPSERT (обновляет или добавляет)          │
└───────────────────────┬─────────────────────────────────┘
                        │
                        │ Запись в целевую БД
                        ▼
┌─────────────────────────────────────────────────────────┐
│              PostgreSQL Database                        │
│                                                         │
│  Целевая таблица с денормализованными данными           │
└─────────────────────────────────────────────────────────┘
```

## Что нужно установить/настроить

### ✅ Уже есть в банке (использовать существующие)

1. **Oracle Database** - база данных источник
2. **Apache Kafka** - шина сообщений для передачи данных
3. **Zookeeper** - служба координации для Kafka (обычно идет вместе с Kafka)
4. **PostgreSQL Database** - целевая база данных

### 📦 Нужно установить как новые сервисы

| Сервис              | Назначение                                            |
|---------------------|-------------------------------------------------------|
| **kafka-connect**   | Коннекторы для чтения из Oracle и записи в PostgreSQL |
| **ksqldb-server**   | Обработка потоков и JOIN данных                       |
| **schema-registry** | Управление схемами данных (нужен для ksqlDB)          |

### ⚙️ Нужно только настроить (донастройка)

1. **Oracle Database**
    - Включить режим ARCHIVELOG
    - Включить supplemental logging
    - Создать пользователя для Debezium с правами на чтение логов

2. **Kafka Connect**
    - Зарегистрировать Debezium Oracle Source Connector
    - Зарегистрировать JDBC Sink Connector

3. **ksqlDB**
    - Создать streams и tables для обработки данных
    - Настроить JOIN операции

4. **PostgreSQL**
    - Создать схему и таблицу для целевых данных
    - Настроить права доступа для Kafka Connect

## Что происходит при изменении данных

### Пример: Добавление нового пользователя

```
1. Пользователь добавляется в Oracle:
   INSERT INTO ORACLE_USERS VALUES (100, 'Иван Иванов', '1990-01-01', 'M', 1, 2);

2. Debezium видит изменение в redo log (< 1 сек)

3. Событие отправляется в Kafka топик oracle_cdc.ORACLEUSER.ORACLE_USERS

4. ksqlDB читает событие и делает JOIN:
   - Берет role_id = 1 → ищет в ORACLE_USERS_ROLE → получает "Admin"
   - Берет grant_id = 2 → ищет в ORACLE_USERS_GRANT → получает "ReadWrite"

5. ksqlDB отправляет обогащенные данные в топик postgres_users_enriched:
   {id: 100, name: "Иван Иванов", birth_date: "1990-01-01", 
    gender: "M", role: "Admin", grant_field: "ReadWrite"}

6. JDBC Sink Connector читает из топика и записывает в PostgreSQL

7. В таблице postgres.postgres_users появляется новая запись (< 1 сек от начала)
```